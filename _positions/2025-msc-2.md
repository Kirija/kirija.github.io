---
title: "Réseaux de neurones lipschitziens et chiffrement homomorphe"
collection: positions
type: "Maitrise"
permalink: /positions/2025-msc-2
venue: "UQAM"
date: 2024-11-13
location: "Montreal, Québec, Canada"
available: true
funding: false
level: MSc
people: Marc-Olivier Killijian
---

### Contexte

Le chiffrement homomorphe est une avancée majeure en cryptographie, permettant d’effectuer des calculs directement sur des données chiffrées sans nécessiter leur déchiffrement préalable. Les schémas basés sur le problème Learning With Errors (LWE), fondés sur des réseaux euclidiens, ont rendu possible la construction de nombreux systèmes de chiffrement homomorphe. Ces constructions partagent une caractéristique essentielle : la gestion d’un bruit nécessaire à leur sécurité, mais qui altère progressivement la précision des calculs. Longtemps, ce bruit a représenté le principal obstacle au développement du chiffrement homomorphe, jusqu’à ce que Gentry propose en 2009 la technique du bootstrapping, qui permit de gérer ce bruit et ouvrit la voie à plusieurs générations de schémas, chacun avec ses particularités. Parmi les schémas de dernière génération, TFHE (Torus Fully Homomorphic Encryption) se distingue par sa capacité à évaluer n’importe quelle fonction grâce au bootstrapping fonctionnel (ou programmable). Cependant, TFHE présente une limitation importante : il ne peut traiter nativement que des entiers de 8 bits au maximum, 4 bits étant souvent préférables pour une meilleure efficacité. Ces contraintes posent des défis pour les applications nécessitant une haute précision, comme l’apprentissage automatique.

Les réseaux de neurones lipschitziens sont une catégorie de modèles d’apprentissage profond qui possèdent des propriétés de robustesse aux variations de l’entrée. Un réseau lipschitzien est conçu pour que de petites variations des données d’entrée produisent des changements proportionnellement limités dans la sortie du modèle. Une méthode efficace pour concevoir ces réseaux est l’utilisation de la fonction d’activation GroupSort, introduite par Anil et al. en 2019. GroupSort divise les pré-activations d’une couche en groupes de taille fixe et trie chaque groupe en ordre croissant, par exemple, en groupes de cinq éléments. En utilisant GroupSort avec des contraintes sur les poids du réseau, telles que la normalisation, on obtient un modèle stable et robuste, capable d’approximer des fonctions ayant des propriétés de continuité et de régularité. Cette technique améliore la résistance du réseau aux perturbations des données d’entrée.

Le défi réside donc dans le fait de combiner le schéma de chiffrement homomorphe TFHE avec des réseaux de neurones lipschitziens pour permettre une inférence sécurisée sur des données chiffrées. TFHE impose des contraintes de précision, limitant la taille des valeurs manipulées, bien que toutes les opérations nécessaires puissent être effectuées tant qu’elles sont discrétisables et que leur résultat peut être stocké dans des tables de correspondance (Look-Up Tables). Par ailleurs, les réseaux de neurones lipschitziens (LNN) avec la fonction d’activation GroupSort sont envisagés comme une solution compatible avec TFHE, à condition de disposer d’un algorithme de tri performant sur données chiffrées. De plus, comme la plupart des algorithmes de tri homomorphes, surtout ceux basés sur TFHE, sont conçus pour des valeurs entières, il est nécessaire de contraindre les poids du modèle à rester entiers. La technique de Quantized Aware Training (QAT) s’avère être une solution efficace pour y parvenir, en adaptant l’entraînement du réseau à ces contraintes.

L’objectif de ce travail sera donc de concevoir, entraîner et évaluer un réseau de neurones lipschitzien compatible avec TFHE, capable de réaliser des inférences sécurisées sur des données chiffrées tout en intégrant les contraintes de quantification et de robustesse nécessaires. 

### Contact

Me contacter ([killijian.marc-olivier.2@uqam.ca](killijian.marc-olivier.2@uqam.ca)) par courriel pour discuter de ce sujet et de vos intérêts.
